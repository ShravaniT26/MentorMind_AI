MentorMindAI â€“ Smart Video Evaluation & Accessibility Engine

MentorMindAI is an AI-powered backend system that evaluates teaching quality from recorded videos and converts videos into multiple accessibility modes â€” Blind Mode, Deaf Mode, and Easy Mode.

The platform leverages ONNX machine-learning models, FastAPI, and asynchronous processing to deliver scalable, reproducible, and fair video evaluations.

ðŸš€ Project Overview

MentorMindAI provides two core capabilities:

1ï¸âƒ£ Video Scoring System (AI Evaluation)

Upload a mentorâ€™s teaching video and receive objective evaluation scores for:

Clarity

Engagement

Pace

Filler Word Usage

Technical Depth

Weighted Overall Score

ðŸ§  Models Used (ONNX)

clarity_model.onnx

engagement_cnn.onnx

pace_model.onnx

filler_model.onnx

tech_depth_model.onnx

Each model focuses on a specific teaching metric and contributes to a deterministic final score.

2ï¸âƒ£ Accessibility Modes

Convert uploaded videos into inclusive formats for diverse learners:

ðŸ”Š Blind Mode

Generates audio narration of visual and spoken content

ðŸ“ Deaf Mode

Generates subtitles (.srt) using Whisper Speech-to-Text

ðŸ“– Easy Mode

Produces simplified narration

Uses text summarization + Text-to-Speech (TTS)

ðŸ§± Project Architecture Overview
ðŸ“¦ MentorMindAI
 â”£ backend/
 â”‚ â”£ app/
 â”‚ â”‚ â”£ api/v1/
 â”‚ â”‚ â”‚ â”£ routes_upload.py      â†’ Upload & conversion APIs
 â”‚ â”‚ â”£ services/
 â”‚ â”‚ â”‚ â”£ video_scoring.py      â†’ ONNX scoring engine
 â”‚ â”‚ â”‚ â”£ mode_blind.py         â†’ Blind mode processing
 â”‚ â”‚ â”‚ â”£ mode_deaf.py          â†’ Deaf mode (subtitles)
 â”‚ â”‚ â”‚ â”£ mode_easy.py          â†’ Easy mode narration
 â”‚ â”‚ â”‚ â”£ video_processor.py    â†’ Video & audio utilities
 â”‚ â”‚ â”£ main.py                 â†’ FastAPI entry point
 â”£ models/
 â”‚ â”£ clarity_model.onnx
 â”‚ â”£ engagement_cnn.onnx
 â”‚ â”£ pace_model.onnx
 â”‚ â”£ filler_model.onnx
 â”‚ â”£ tech_depth_model.onnx
 â”£ frontend/ (optional)
 â”£ README.md
 â”£ requirements.txt

ðŸ§  System Architecture Flow
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚          Frontend            â”‚
                        â”‚        (React + Vite)        â”‚
                        â”‚ â”€ Video Upload               â”‚
                        â”‚ â”€ Results Dashboard          â”‚
                        â”‚ â”€ Accessibility Controls     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â”‚ REST API
                                        â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚           FastAPI API         â”‚
                        â”‚   /api/v1/upload              â”‚
                        â”‚   /api/v1/score               â”‚
                        â”‚   /api/v1/convert             â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                          Upload Video  â”‚   Queue Task
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â–¼                â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚     Storage     â”‚   â”‚      Redis       â”‚
                   â”‚ (Local / S3)    â”‚   â”‚  Task Queue      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                       â”‚
                           â”‚ Fetch video           â”‚ Background Job
                           â”‚                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                    â”‚           Worker Engine              â”‚
                    â”‚ â”€ Audio Extraction                  â”‚
                    â”‚ â”€ Transcript (Whisper ASR)          â”‚
                    â”‚ â”€ Frame & Feature Extraction        â”‚
                    â”‚ â”€ ONNX Model Inference              â”‚
                    â”‚ â”€ Deterministic Scoring              â”‚
                    â”‚ â”€ Accessibility Mode Generation     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ Store results
                              â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Results Store â”‚
                     â”‚ (DB / JSON)     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    Frontend Fetches Final Results
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Results Dashboard â”‚
                    â”‚ Scores + Graphs   â”‚
                    â”‚ Accessibility     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-repo/MentorMindAI
cd MentorMindAI

2ï¸âƒ£ Create Virtual Environment
python -m venv venv

3ï¸âƒ£ Activate Environment

Windows

venv\Scripts\activate


Mac / Linux

source venv/bin/activate

4ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

5ï¸âƒ£ Install FFmpeg (Required)

Windows

choco install ffmpeg


Mac

brew install ffmpeg

6ï¸âƒ£ Generate Dummy ONNX Models (Demo Mode)
python models/generate_dummy_models.py

â–¶ï¸ How to Run Locally

Start the FastAPI server:

uvicorn backend.app.main:app --reload


Server URL:

http://localhost:8000


Swagger Docs:

http://localhost:8000/docs

ðŸ”¥ API Endpoints
1ï¸âƒ£ Upload Video & Get Scores

POST /upload/video

Response

{
  "file_id": "56c7e543-0b4e-49f6-9509-fb6cbe6bc9b6",
  "scores": {
    "clarity": 0.82,
    "engagement": 0.56,
    "pace": 0.74,
    "filler": 0.21,
    "tech": 0.88
  },
  "overall_score": 0.73
}

2ï¸âƒ£ Convert Video into Accessibility Mode

POST /convert?mode=blind
POST /convert?mode=deaf
POST /convert?mode=easy

Response

{
  "status": "success",
  "output_path": "/mnt/data/uploads/video_deaf_mode.srt"
}

ðŸ§ª Example Input & Output
Input

MP4 Video

Mode: deaf

Output

Extracted Audio

Whisper ASR Transcript

Subtitle File (.srt)

1
00:00:01,000 --> 00:00:03,000
Hello students, today we will learn AI.

ðŸ“¦ List of Dependencies

fastapi

uvicorn[standard]

python-multipart

celery

redis

pydantic

requests

python-dotenv

numpy

onnxruntime

opencv-python

pydub

moviepy

speechrecognition

transformers

torch

pillow

âœ¨ Contributions

Shravani Tanksale (AI Lead)
Built scoring models, ONNX inference pipeline, backend logic, accessibility modes, and end-to-end system integration.

Vidyankshini Vibhute (Frontend)
Developed UI, dashboards, visualizations, upload workflows, and frontend-backend integration.

Devika Mule (Cloud / DevOps)
Designed cloud architecture, storage integration, async processing pipeline, deployment strategy, and performance optimizations.